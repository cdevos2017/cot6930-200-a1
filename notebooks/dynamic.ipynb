{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template Prompting\n",
    "\n",
    "Prompt Template Prompting refers to a technique where predefined templates are used to construct effective prompts that guide large language models (LLMs) to generate responses tailored to specific use cases. The templates typically contain static text combined with dynamic input variables, allowing for consistent, reusable, and customizable prompts.\n",
    "\n",
    "Prompt templates are widely used across various domains, such as:\n",
    "* **Question Generation**: Templates can generate quiz questions by filling in variables related to topics.\n",
    "* **Text Summarization**: Static instructions combined with variable documents or inputs allow flexible summarization.\n",
    "* **Coding Assistance**: Dynamic prompts help LLMs generate code snippets for different programming tasks.\n",
    "\n",
    "## References:\n",
    "\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fprompt_template.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Write a Python function to calculate the Fibonacci sequence\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: {\"quality_score\": 0.7, \"improved_prompt\": \"Write a Python function to calculate the Fibonacci sequen...\n",
      "Iteration 1:\n",
      "Current quality: 0.7\n",
      "Reasoning: The prompt quality is good, but could be improved by specifying the mathematical technique used (iterative approach). The role and technique are suitable for this task.\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Write a Python function to calculate the Fibonacci sequence using an iterative approach\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: {\"quality_score\": 0.8, \"improved_prompt\": \"Write a Python function to calculate the Fibonacci sequen...\n",
      "Iteration 2:\n",
      "Current quality: 0.8\n",
      "Reasoning: The current prompt quality is high, but an improved version would provide more context to the task.\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Write a Python function to calculate the Fibonacci sequence using an iterative approach (Please refine this further)\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: {\"quality_score\":0.7,\"improved_prompt\":\"Write a Python function to calculate the Fibonacci sequence ...\n",
      "Iteration 3:\n",
      "Current quality: 0.7\n",
      "Reasoning: The quality score is 0.7 as it requires refinement but meets basic requirements for clarity and specificity. The improved prompt is more detailed, providing a clear direction for the user. The suggested role and technique are optimal for mathematical problems requiring iterative approaches.\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Write a Python function to calculate the Fibonacci sequence using an iterative approach with clear explanations and examples\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: {\"quality_score\":0.8,\"improved_prompt\":\"Write a Python function to calculate the Fibonacci sequence ...\n",
      "Iteration 4:\n",
      "Current quality: 0.8\n",
      "Reasoning: The original prompt was clear and concise, but could benefit from more specific guidance on edge cases. The improved prompt adds a bit more complexity to the task while maintaining clarity.\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Write a Python function to calculate the Fibonacci sequence using an iterative approach with clear explanations and examples, including code snippets and potential edge cases\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: {\"quality_score\": 0.8, \"improved_prompt\": \"Write a Python function to calculate the Fibonacci sequen...\n",
      "Iteration 5:\n",
      "Current quality: 0.8\n",
      "Reasoning: Improved prompt to include potential edge cases and related topics.\n",
      "\n",
      "================================================================================\n",
      "  REFINED CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "{\n",
      "  \"quality_score\": 0.8,\n",
      "  \"improved_prompt\": \"Write a Python function to calculate the Fibonacci sequence using an iterative approach\",\n",
      "  \"role\": \"Mathematician\",\n",
      "  \"technique\": \"chain_of_thought\",\n",
      "  \"task_type\": \"math\",\n",
      "  \"template\": \"{query}\",\n",
      "  \"parameters\": {\n",
      "    \"temperature\": 0.5,\n",
      "    \"num_ctx\": 1024,\n",
      "    \"num_predict\": 512\n",
      "  },\n",
      "  \"reasoning\": \"The current prompt quality is high, but an improved version would provide more context to the task.\",\n",
      "  \"metadata\": {\n",
      "    \"original_query\": \"Write a Python function to calculate the Fibonacci sequence\",\n",
      "    \"validation_performed\": true,\n",
      "    \"validation_timestamp\": \"2025-02-24 14:44:21\"\n",
      "  },\n",
      "  \"final_prompt\": \"Write a Python function to calculate the Fibonacci sequence\",\n",
      "  \"iterations_used\": 5,\n",
      "  \"final_quality\": 0.8\n",
      "}\n",
      "\n",
      "\n",
      "================================================================================\n",
      "  GENERATED PROMPT\n",
      "================================================================================\n",
      "\n",
      "Solve this mathematical problem step-by-step: Think through this step-by-step: Write a Python function to calculate the Fibonacci sequence\n",
      "\n",
      "Let's break this down into parts and solve methodically.\n",
      "\n",
      "Show your reasoning clearly.\n",
      "\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': \"Solve this mathematical problem step-by-step: Think through this step-by-step: Write a Python function to calculate the Fibonacci sequence\\n\\nLet's break this down into parts and solve methodically.\\n\\nShow your reasoning clearly.\"}], 'parameters': {'temperature': 0.5, 'num_ctx': 1024, 'num_predict': 512}}\n",
      "\n",
      "================================================================================\n",
      "  MODEL RESPONSE\n",
      "================================================================================\n",
      "\n",
      "# Step 1: Define the Problem\n",
      "We need to write a Python function that calculates the Fibonacci sequence. The Fibonacci sequence is a series of numbers in which each number is the sum of the two preceding ones, usually starting with 0 and 1.\n",
      "\n",
      "# Step 2: Understand the Base Cases\n",
      "The base cases for this problem are:\n",
      "- F(0) = 0 (the first number in the Fibonacci sequence)\n",
      "- F(1) = 1 (the second number in the Fibonacci sequence)\n",
      "\n",
      "# Step 3: Decide on a Approach\n",
      "There are several ways to solve this problem, but one common approach is to use recursion. This involves writing a function that calls itself to calculate each subsequent number in the sequence.\n",
      "\n",
      "Here's how we can define our Python function:\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    # Base cases\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    \n",
      "    # Recursive case: Calculate the nth Fibonacci number using the (n-1)th and (n-2)th numbers\n",
      "    else:\n",
      "        return fibonacci(n-1) + fibonacci(n-2)\n",
      "```\n",
      "\n",
      "However, this recursive approach is not very efficient. We can improve it by storing previously calculated values in a list.\n",
      "\n",
      "# Step 4: Create a Memoized Version of the Function\n",
      "We'll create an iterative version using memoization to avoid repeated calculations:\n",
      "\n",
      "```python\n",
      "def fibonacci(n, memo={}):\n",
      "    # Base cases\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    \n",
      "    # Check if we've already calculated this number\n",
      "    if n in memo:\n",
      "        return memo[n]\n",
      "    \n",
      "    # Calculate the nth Fibonacci number and store it for next time\n",
      "    else:\n",
      "        result = fibonacci(n-1, memo) + fibonacci(n-2, memo)\n",
      "        memo[n] = result\n",
      "        return result\n",
      "```\n",
      "\n",
      "# Step 5: Test Our Function\n",
      "We should test our function with some examples:\n",
      "\n",
      "```python\n",
      "print(fibonacci(10))  # Expected output: 55\n",
      "```\n",
      "\n",
      "This version of the function is much more efficient than the recursive one, especially for large values of n.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from prompt.prompt_refiner import iterative_prompt_refinement, format_final_prompt\n",
    "from prompt.utils import format_response, print_step\n",
    "from config._pipeline import create_payload, model_req\n",
    "\n",
    "# Original query\n",
    "MESSAGE = \"\"\n",
    "\n",
    "# Get refined configuration with improved template usage\n",
    "refined_config = iterative_prompt_refinement(MESSAGE)\n",
    "print_step(\"REFINED CONFIGURATION\", refined_config)\n",
    "\n",
    "# Format the final prompt\n",
    "PROMPT = format_final_prompt(refined_config, MESSAGE)\n",
    "print_step(\"GENERATED PROMPT\", PROMPT, is_json=False)\n",
    "\n",
    "# Configure model with optimized parameters\n",
    "payload = create_payload(\n",
    "    target=\"open-webui\",\n",
    "    model=\"llama3.2:latest\", \n",
    "    prompt=PROMPT,\n",
    "    **refined_config[\"parameters\"]\n",
    ")\n",
    "\n",
    "# Get and format response\n",
    "time, response = model_req(request_payload=payload)\n",
    "formatted_response = format_response(response, refined_config.get(\"task_type\"))\n",
    "print_step(\"MODEL RESPONSE\", formatted_response, is_json=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
