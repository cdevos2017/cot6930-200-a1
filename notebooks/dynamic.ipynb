{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template Prompting\n",
    "\n",
    "Prompt Template Prompting refers to a technique where predefined templates are used to construct effective prompts that guide large language models (LLMs) to generate responses tailored to specific use cases. The templates typically contain static text combined with dynamic input variables, allowing for consistent, reusable, and customizable prompts.\n",
    "\n",
    "Prompt templates are widely used across various domains, such as:\n",
    "* **Question Generation**: Templates can generate quiz questions by filling in variables related to topics.\n",
    "* **Text Summarization**: Static instructions combined with variable documents or inputs allow flexible summarization.\n",
    "* **Coding Assistance**: Dynamic prompts help LLMs generate code snippets for different programming tasks.\n",
    "\n",
    "## References:\n",
    "\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fprompt_template.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Testing the new Llama 3.2 model with a complex prompt. Please provide a detailed response.\"\\n        Current configuration:\\n        - Role: Assistant\\n        - Technique: socratic\\n        - Task Type: explanation\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: !!ERROR!! Request failed! You need to adjust config with URL(None)...\n",
      "No JSON object found in response\n",
      "Iteration 1:\n",
      "Current quality: 0.7\n",
      "Reasoning: Default configuration for mathematical calculation\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Testing the new Llama 3.2 model with a complex prompt. Please provide a detailed response. (Please refine this further)\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: !!ERROR!! Request failed! You need to adjust config with URL(None)...\n",
      "No JSON object found in response\n",
      "Iteration 2:\n",
      "Current quality: 0.7\n",
      "Reasoning: Default configuration for mathematical calculation\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Testing the new Llama 3.2 model with a complex prompt. Please provide a detailed response. (Please refine this further) (Please refine this further)\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: !!ERROR!! Request failed! You need to adjust config with URL(None)...\n",
      "No JSON object found in response\n",
      "Iteration 3:\n",
      "Current quality: 0.7\n",
      "Reasoning: Default configuration for mathematical calculation\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Testing the new Llama 3.2 model with a complex prompt. Please provide a detailed response. (Please refine this further) (Please refine this further) (Please refine this further)\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: !!ERROR!! Request failed! You need to adjust config with URL(None)...\n",
      "No JSON object found in response\n",
      "Iteration 4:\n",
      "Current quality: 0.7\n",
      "Reasoning: Default configuration for mathematical calculation\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Testing the new Llama 3.2 model with a complex prompt. Please provide a detailed response. (Please refine this further) (Please refine this further) (Please refine this further) (Please refine this further)\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: !!ERROR!! Request failed! You need to adjust config with URL(None)...\n",
      "No JSON object found in response\n",
      "Iteration 5:\n",
      "Current quality: 0.7\n",
      "Reasoning: Default configuration for mathematical calculation\n",
      "Warning: No {query} placeholder in template: Calculate the following mathematical expression step-by-step: Solve this mathematical problem step-by-step: Think through this step-by-step: Testing the new Llama 3.2 model with a complex prompt. Please provide a detailed response.     \n",
      "\n",
      "Let's break this down into parts and solve methodically.\n",
      "\n",
      "Show your reasoning clearly.. Using current query.\n",
      "\n",
      "================================================================================\n",
      "  REFINED CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "{\n",
      "  \"quality_score\": 0.7,\n",
      "  \"improved_prompt\": null,\n",
      "  \"role\": \"Mathematician\",\n",
      "  \"technique\": \"chain_of_thought\",\n",
      "  \"task_type\": \"math\",\n",
      "  \"template\": \"Calculate the following mathematical expression step-by-step: {query}\",\n",
      "  \"parameters\": {\n",
      "    \"temperature\": 0.2,\n",
      "    \"num_ctx\": 2048,\n",
      "    \"num_predict\": 1024\n",
      "  },\n",
      "  \"reasoning\": \"Default configuration for mathematical calculation\",\n",
      "  \"metadata\": {\n",
      "    \"original_query\": \"Testing the new Llama 3.2 model with a complex prompt. Please provide a detailed response.\",\n",
      "    \"validation_performed\": true,\n",
      "    \"validation_timestamp\": \"2025-02-27 15:42:30\"\n",
      "  },\n",
      "  \"final_prompt\": \"Testing the new Llama 3.2 model with a complex prompt. Please provide a detailed response.\",\n",
      "  \"iterations_used\": 5,\n",
      "  \"final_quality\": 0.7\n",
      "}\n",
      "\n",
      "Warning: No {query} placeholder in template: Testing the new Llama 3.2 model with a complex prompt. Please provide a detailed response.. Using current query.\n",
      "\n",
      "================================================================================\n",
      "  GENERATED PROMPT\n",
      "================================================================================\n",
      "\n",
      "Solve this mathematical problem step-by-step: Think through this step-by-step: Testing the new Llama 3.2 model with a complex prompt. Please provide a detailed response.\n",
      "\n",
      "Let's break this down into parts and solve methodically.\n",
      "\n",
      "Show your reasoning clearly.\n",
      "\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': \"Solve this mathematical problem step-by-step: Think through this step-by-step: Testing the new Llama 3.2 model with a complex prompt. Please provide a detailed response.\\n\\nLet's break this down into parts and solve methodically.\\n\\nShow your reasoning clearly.\"}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 1024}}\n",
      "\n",
      "================================================================================\n",
      "  MODEL RESPONSE\n",
      "================================================================================\n",
      "\n",
      "Step 1: !!ERROR!! Request failed! You need to adjust config with URL(None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from prompt.prompt_refiner import iterative_prompt_refinement, format_final_prompt\n",
    "from prompt.utils import format_response, print_step\n",
    "from config._pipeline import create_payload, model_req\n",
    "\n",
    "# Original query\n",
    "MESSAGE = \"Testing the new Llama 3.2 model with a complex prompt. Please provide a detailed response.\"\n",
    "\n",
    "# Get refined configuration with improved template usage\n",
    "refined_config = iterative_prompt_refinement(MESSAGE)\n",
    "print_step(\"REFINED CONFIGURATION\", refined_config)\n",
    "\n",
    "# Format the final prompt\n",
    "PROMPT = format_final_prompt(refined_config, MESSAGE)\n",
    "print_step(\"GENERATED PROMPT\", PROMPT, is_json=False)\n",
    "\n",
    "# Configure model with optimized parameters\n",
    "payload = create_payload(\n",
    "    target=\"open-webui\",\n",
    "    model=\"llama3.2:latest\", \n",
    "    prompt=PROMPT,\n",
    "    **refined_config[\"parameters\"]\n",
    ")\n",
    "\n",
    "# Get and format response\n",
    "time, response = model_req(request_payload=payload)\n",
    "formatted_response = format_response(response, refined_config.get(\"task_type\"))\n",
    "print_step(\"MODEL RESPONSE\", formatted_response, is_json=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
