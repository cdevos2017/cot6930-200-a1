{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template Prompting\n",
    "\n",
    "Prompt Template Prompting refers to a technique where predefined templates are used to construct effective prompts that guide large language models (LLMs) to generate responses tailored to specific use cases. The templates typically contain static text combined with dynamic input variables, allowing for consistent, reusable, and customizable prompts.\n",
    "\n",
    "Prompt templates are widely used across various domains, such as:\n",
    "* **Question Generation**: Templates can generate quiz questions by filling in variables related to topics.\n",
    "* **Text Summarization**: Static instructions combined with variable documents or inputs allow flexible summarization.\n",
    "* **Coding Assistance**: Dynamic prompts help LLMs generate code snippets for different programming tasks.\n",
    "\n",
    "## References:\n",
    "\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fprompt_template.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Write a Python function to calculate the Fibonacci sequence\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: {\"quality_score\": 0.9, \"improved_prompt\": \"Write a clear and concise Python function to calculate th...\n",
      "Iteration 1:\n",
      "Current quality: 0.9\n",
      "Reasoning: The current prompt is well-structured and clear, but could benefit from more specific guidance on the desired output format.\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Write a clear and concise Python function to calculate the Fibonacci sequence\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: {\"quality_score\": 0.7, \"improved_prompt\": \"Write a clear and concise Python function to calculate th...\n",
      "Iteration 2:\n",
      "Current quality: 0.7\n",
      "Reasoning: The original prompt was of high quality but could be improved for better template suitability.\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Write a clear and concise Python function to calculate the Fibonacci sequence in a readable and efficient manner.\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: {\"quality_score\": 0.8, \"improved_prompt\": \"Write a clear and concise Python function to calculate th...\n",
      "Iteration 3:\n",
      "Current quality: 0.8\n",
      "Reasoning: The original prompt is of high quality and effectively conveys the required task. However, adding 'utilizing iteration or recursion' provides further clarity on acceptable methods.\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Write a clear and concise Python function to calculate the Fibonacci sequence in a readable and efficient manner, utilizing iteration or recursion with example usage.\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: {\"quality_score\": 0.7, \"improved_prompt\": \"Write a clear and concise Python function to calculate th...\n",
      "Iteration 4:\n",
      "Current quality: 0.7\n",
      "Reasoning: The quality score is adjusted because the prompt could be optimized for better performance. The improved prompt includes optimization and example usage to make it more specific.\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': 'You will analyze a user query and provide a JSON response. Your response must ONLY contain valid JSON with no commentary before or after. The JSON must be on a single line with no line breaks within values. All strings must use double quotes. The JSON must be parseable by json.loads().\\n\\n\\n        Evaluate this candidate prompt: \"Write a clear and concise Python function to calculate the Fibonacci sequence in a readable and efficient manner, utilizing either iteration or recursion with example usage for optimization.\"\\n        Current configuration:\\n        - Role: Mathematician\\n        - Technique: chain_of_thought\\n        - Task Type: math\\n        \\n        1. Rate the current prompt quality from 0.0 to 1.0\\n        2. Provide an improved version even if quality is high\\n        3. Determine if the current role and technique are optimal for this task\\n        \\n        Return your analysis in JSON format:\\n        {\\n            \"quality_score\": [score between 0-1],\\n            \"improved_prompt\": \"[refined prompt]\",\\n            \"role\": \"[appropriate expert role]\",\\n            \"technique\": \"[suggested prompt technique]\",\\n            \"task_type\": \"[specific task category]\",\\n            \"template\": \"[prompt template with {query} placeholder]\",\\n            \"parameters\": {\\n                \"temperature\": [appropriate value],\\n                \"num_ctx\": [appropriate value],\\n                \"num_predict\": [appropriate value]\\n            },\\n            \"reasoning\": \"[explanation of changes made]\"\\n        }\\n        '}], 'parameters': {'temperature': 0.2, 'num_ctx': 2048, 'num_predict': 512}}\n",
      "Raw response to parse: {\"quality_score\": 0.85, \"improved_prompt\": \"Write a clear and concise Python function to calculate t...\n",
      "Iteration 5:\n",
      "Current quality: 0.85\n",
      "Reasoning: The original prompt is well-structured and clear. The suggested improvement aims to make it more specific by mentioning a production-ready codebase, which could help generate more realistic and applicable code.\n",
      "Error in format_prompt_with_template: 'technique'\n",
      "\n",
      "================================================================================\n",
      "  REFINED CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "{\n",
      "  \"quality_score\": 0.9,\n",
      "  \"improved_prompt\": \"Write a clear and concise Python function to calculate the Fibonacci sequence\",\n",
      "  \"role\": \"Mathematician\",\n",
      "  \"technique\": \"chain_of_thought\",\n",
      "  \"task_type\": \"math\",\n",
      "  \"template\": \"{query} Write a {technique} to solve the problem of calculating the Fibonacci sequence in Python\",\n",
      "  \"parameters\": {\n",
      "    \"temperature\": 0.7,\n",
      "    \"num_ctx\": 1024,\n",
      "    \"num_predict\": 512\n",
      "  },\n",
      "  \"reasoning\": \"The current prompt is well-structured and clear, but could benefit from more specific guidance on the desired output format.\",\n",
      "  \"metadata\": {\n",
      "    \"original_query\": \"Write a Python function to calculate the Fibonacci sequence\",\n",
      "    \"validation_performed\": true,\n",
      "    \"validation_timestamp\": \"2025-02-22 22:00:10\"\n",
      "  },\n",
      "  \"final_prompt\": \"Write a Python function to calculate the Fibonacci sequence\",\n",
      "  \"iterations_used\": 5,\n",
      "  \"final_quality\": 0.85\n",
      "}\n",
      "\n",
      "\n",
      "================================================================================\n",
      "  GENERATED PROMPT\n",
      "================================================================================\n",
      "\n",
      "Solve this mathematical problem step-by-step: Think through this step-by-step: Write a Python function to calculate the Fibonacci sequence\n",
      "\n",
      "Let's break this down into parts and solve methodically.\n",
      "\n",
      "Show your reasoning clearly.\n",
      "\n",
      "{'model': 'llama3.2:latest', 'messages': [{'role': 'user', 'content': \"Solve this mathematical problem step-by-step: Think through this step-by-step: Write a Python function to calculate the Fibonacci sequence\\n\\nLet's break this down into parts and solve methodically.\\n\\nShow your reasoning clearly.\"}], 'parameters': {'temperature': 0.7, 'num_ctx': 1024, 'num_predict': 512}}\n",
      "\n",
      "================================================================================\n",
      "  MODEL RESPONSE\n",
      "================================================================================\n",
      "\n",
      "Here's how you can write a Python function to calculate the Fibonacci sequence:\n",
      "\n",
      "### Step 1: Define the Function\n",
      "First, we need to define a function that will hold our code. We'll call it `fibonacci`.\n",
      "\n",
      "```python\n",
      "def fibonacci():\n",
      "```\n",
      "\n",
      "### Step 2: Define Parameters (if necessary)\n",
      "Since the problem is asking us to write a general function for calculating the Fibonacci sequence without specifying any input parameters, we won't need to define any.\n",
      "\n",
      "### Step 3: Generate the Sequence\n",
      "Next, we'll generate the sequence. The Fibonacci sequence starts with two numbers, usually 0 and 1, but we can start from any given number or set of starting values. Here's how you might do it:\n",
      "\n",
      "```python\n",
      "    # Start sequence with first two elements (you could use other numbers here)\n",
      "    a, b = 0, 1\n",
      "\n",
      "    while True:\n",
      "        yield a\n",
      "        # Generate next element in the sequence\n",
      "        a, b = b, a + b\n",
      "```\n",
      "\n",
      "### Step 4: Test the Function\n",
      "Finally, we'll test our function to make sure it works. Here's an example of how you might do that:\n",
      "\n",
      "```python\n",
      "# Create a list of the first 10 elements in the sequence\n",
      "sequence = list(fibonacci())[:10]\n",
      "print(sequence)\n",
      "```\n",
      "\n",
      "When we run this code, `fibonacci()` will generate the Fibonacci sequence starting from 0 and 1. The `[0:10]` is used to get only the first ten elements.\n",
      "\n",
      "### Step 5: Make it into a Full Function\n",
      "Here's the full function:\n",
      "\n",
      "```python\n",
      "def fibonacci():\n",
      "    # Start sequence with first two elements\n",
      "    a, b = 0, 1\n",
      "\n",
      "    while True:\n",
      "        yield a\n",
      "        # Generate next element in the sequence\n",
      "        a, b = b, a + b\n",
      "\n",
      "\n",
      "# Create a list of the first n elements in the sequence\n",
      "def get_fibonacci(n):\n",
      "    sequence = fibonacci()\n",
      "    return [next(sequence) for _ in range(n)]\n",
      "\n",
      "print(get_fibonacci(10))\n",
      "```\n",
      "\n",
      "This function will print the first ten numbers in the Fibonacci sequence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from prompt.prompt_refiner import iterative_prompt_refinement, format_final_prompt\n",
    "from prompt.utils import format_response, print_step\n",
    "from config._pipeline import create_payload, model_req\n",
    "\n",
    "# Original query\n",
    "MESSAGE = \"Write a Python function to calculate the Fibonacci sequence\"\n",
    "\n",
    "# Get refined configuration with improved template usage\n",
    "refined_config = iterative_prompt_refinement(MESSAGE)\n",
    "print_step(\"REFINED CONFIGURATION\", refined_config)\n",
    "\n",
    "# Format the final prompt\n",
    "PROMPT = format_final_prompt(refined_config, MESSAGE)\n",
    "print_step(\"GENERATED PROMPT\", PROMPT, is_json=False)\n",
    "\n",
    "# Configure model with optimized parameters\n",
    "payload = create_payload(\n",
    "    target=\"open-webui\",\n",
    "    model=\"llama3.2:latest\", \n",
    "    prompt=PROMPT,\n",
    "    **refined_config[\"parameters\"]\n",
    ")\n",
    "\n",
    "# Get and format response\n",
    "time, response = model_req(request_payload=payload)\n",
    "formatted_response = format_response(response, refined_config.get(\"task_type\"))\n",
    "print_step(\"MODEL RESPONSE\", formatted_response, is_json=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
